{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 1. IMPORTS & CONFIGURATION\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Using Handcrafted Features and ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATASET_PATH = \"../../dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "IMAGE_SIZE = (128, 128)\n",
    "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
    "# FEATURES_FOLDER = \"testing_features\"\n",
    "FEATURES_FOLDER = \"enhanced_features\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(FEATURES_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 2. FEATURE EXTRACTION (HOG)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4094 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# def extract_hog_features(img_path):\n",
    "#     \"\"\" Extract HOG features from an image \"\"\"\n",
    "#     try:\n",
    "#         img = cv2.imread(img_path)\n",
    "#         if img is None:\n",
    "#             return None\n",
    "#         img = cv2.resize(img, IMAGE_SIZE)\n",
    "#         hog_features = [hog(channel, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False)\n",
    "#                         for channel in cv2.split(img)]\n",
    "#         return np.hstack(hog_features)\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "def extract_features(img_path):\n",
    "    \"\"\" Extract HOG, Color Histogram, and LBP features from an image \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        img = cv2.resize(img, IMAGE_SIZE)\n",
    "\n",
    "        # HOG Features\n",
    "        hog_features = [hog(channel, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False)\n",
    "                        for channel in cv2.split(img)]\n",
    "        hog_features = np.hstack(hog_features)\n",
    "\n",
    "        # Color Histogram Features (using HSV)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hist_features = np.concatenate([cv2.calcHist([hsv], [i], None, [8], [0, 256]).flatten() for i in range(3)])\n",
    "\n",
    "        # Local Binary Patterns (LBP)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n",
    "        lbp_hist = lbp_hist.astype(\"float\")\n",
    "        lbp_hist /= (lbp_hist.sum() + 1e-7)  # Normalize\n",
    "\n",
    "        # Edge Histogram\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        edge_hist, _ = np.histogram(edges, bins=8, range=(0, 256))\n",
    "        edge_hist = edge_hist.astype(\"float\")\n",
    "        edge_hist /= (edge_hist.sum() + 1e-7)  # Normalize\n",
    "\n",
    "        # Concatenate all features\n",
    "        final_features = np.hstack([hog_features, hist_features, lbp_hist, edge_hist])\n",
    "\n",
    "        # Ensure feature size consistency\n",
    "        if final_features.shape[0] > 24300:\n",
    "            final_features = final_features[:24300]  # Truncate if too large\n",
    "        elif final_features.shape[0] < 24300:\n",
    "            final_features = np.pad(final_features, (0, 24300 - final_features.shape[0]))  # Pad if too small\n",
    "\n",
    "        return final_features\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_image(args):\n",
    "    \"\"\" Process single image for multiprocessing \"\"\"\n",
    "    img_path, label = args\n",
    "    features = extract_features(img_path)\n",
    "    return (features, label) if features is not None else (None, None)\n",
    "\n",
    "def load_dataset_parallel():\n",
    "    \"\"\" Load dataset and extract features in parallel \"\"\"\n",
    "    image_paths_labels = [(os.path.join(DATASET_PATH, cat, f), label)\n",
    "                            for label, cat in enumerate(CATEGORIES)\n",
    "                            for f in os.listdir(os.path.join(DATASET_PATH, cat))]\n",
    "\n",
    "    X_hog, y_hog = [], []\n",
    "    with Pool(max(cpu_count() - 1, 1)) as pool:\n",
    "        results = list(tqdm(pool.imap(process_image, image_paths_labels), total=len(image_paths_labels)))\n",
    "\n",
    "    for features, label in results:\n",
    "        if features is not None:\n",
    "            X_hog.append(features)\n",
    "            y_hog.append(label)\n",
    "\n",
    "    return np.array(X_hog), np.array(y_hog)\n",
    "\n",
    "# Run feature extraction only if data is missing\n",
    "if not os.path.exists(os.path.join(FEATURES_FOLDER, \"X.npy\")):\n",
    "    print(\"Extracting features...\")\n",
    "    X_hog, y_hog = load_dataset_parallel()\n",
    "    np.save(os.path.join(FEATURES_FOLDER, \"X.npy\"), X_hog)\n",
    "    np.save(os.path.join(FEATURES_FOLDER, \"y.npy\"), y_hog)\n",
    "    print(f\"Feature extraction completed. Saved {X_hog.shape}.\")\n",
    "else:\n",
    "    print(\"Loading pre-extracted features...\")\n",
    "    X_hog = np.load(os.path.join(FEATURES_FOLDER, \"X.npy\"))\n",
    "    y_hog = np.load(os.path.join(FEATURES_FOLDER, \"y.npy\"))\n",
    "\n",
    "# Split dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# 3. CLASSIFICATION\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "sns.heatmap(svm_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
